# -*- coding: utf-8 -*-
"""Face Mask Detection Task .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zK9I11IbqrOwegY7zS8usTnOLAsdbt5_
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import cv2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, Flatten, Dropout, AveragePooling2D, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix, classification_report

dataset_path = "/content/drive/MyDrive/ProgressSoft /Face Mask Detection /Face Mask Dataset" #DataSetLink:https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset
train_dir = os.path.join(dataset_path, "Train")
val_dir = os.path.join(dataset_path, "Validation")
test_dir = os.path.join(dataset_path, "Test")

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0001

#Data Augumentaion performed on training data
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    zoom_range=0.15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    horizontal_flip=True,
    fill_mode="nearest"
)

val_datagen = ImageDataGenerator(rescale=1.0/255) #Normlisation On Validation data
test_datagen = ImageDataGenerator(rescale=1.0/255) #Normlisation On Test data

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="binary"
)

val_generator = val_datagen.flow_from_directory(
    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="binary"
)

test_generator = test_datagen.flow_from_directory(
    test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode="binary", shuffle=False
)

"""Class 0 for wearing a Mask and Class 1 for not wearing A mask"""

# Function to visualize some training images
def visualize_images(generator, title):
    images, labels = next(generator)
    fig, axes = plt.subplots(3, 5, figsize=(10, 6))
    fig.suptitle(title, fontsize=16)
    for i, ax in enumerate(axes.flat):
        ax.imshow(images[i])
        ax.set_title(f"Label: {int(labels[i])}")
        ax.axis("off")
    plt.show()

# Visualize Training and Validation Images
visualize_images(train_generator, "Sample Training Images")
visualize_images(val_generator, "Sample Validation Images")

# load the MobileNetV2 network, ensuring the head FC layer sets are left off
base_model = MobileNetV2(weights="imagenet", include_top=False, input_tensor=Input(shape=(224, 224, 3)))

# Define custom classifier on top of MobileNetV2
x = base_model.output
x = AveragePooling2D(pool_size=(7, 7))(x)
x = Flatten(name="flatten")(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation="sigmoid")(x)  # Binary classification (Mask or No Mask)

# loop over all layers in the base model and freeze them so they will *not* be updated during the first training process
for layer in base_model.layers:
    layer.trainable = False

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(loss="binary_crossentropy", optimizer=Adam(learning_rate=LEARNING_RATE), metrics=["accuracy"])

"""# Saving Checkpoints"""

full_path = os.path.join(dataset_path, "training_1")

os.makedirs(full_path, exist_ok=True)

checkpoint_path = os.path.join(full_path, "cp.weights.h5") # Since you're only saving weights, you should use the .weights.h5 extension. If you're saving the whole model, you would use the .keras extension instead
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

"""# Training"""

early_stop = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    validation_data=val_generator,
    validation_steps=len(val_generator),
    epochs=10,
    callbacks=[early_stop,cp_callback]

)

os.listdir(checkpoint_dir)

# Loads the weights
model.load_weights(checkpoint_path)

model.compile(loss="binary_crossentropy", optimizer=Adam(), metrics=["accuracy"])

test_generator.reset()
predictions = (model.predict(test_generator) > 0.5).astype("int32")
true_labels = test_generator.classes

print(predictions.shape, true_labels.shape)

print(set(true_labels))

test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy*100:.2f}%")

model_path = os.path.join(dataset_path, "saved_model")
os.makedirs(model_path, exist_ok=True)

# Save the entire model as a SavedModel.
!mkdir -p saved_model
tf.saved_model.save(model, 'saved_model')

conf_matrix = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["WithMask", "WithoutMask"], yticklabels=["WithMask", "WithoutMask"])
plt.show()

# Print classification report
print("Classification Report:\n", classification_report(true_labels, predictions, target_names=["Mask", "No Mask"]))

# Function to visualize model predictions
def visualize_predictions(generator, model, title):
    images, labels = next(generator)
    predictions = model.predict(images)
    predictions = np.round(predictions).astype(int).flatten()

    fig, axes = plt.subplots(3, 5, figsize=(10, 6))
    fig.suptitle(title, fontsize=16)

    for i, ax in enumerate(axes.flat):
        ax.imshow(images[i])
        ax.set_title(f"True: {int(labels[i])}, Pred: {predictions[i]}")
        ax.axis("off")

    plt.show()

# Visualize predictions on test images
visualize_predictions(test_generator, model, "Test Predictions")

def visualize_predictions(generator, model, title, samples_per_class=5):
    # Lists to store images for each class
    class_0_images = []  # No mask
    class_1_images = []  # With mask
    class_0_labels = []
    class_1_labels = []

    # Keep getting batches until we have enough samples of each class
    while len(class_0_images) < samples_per_class or len(class_1_images) < samples_per_class:
        images, labels = next(generator)
        predictions = model.predict(images)
        predictions = np.round(predictions).astype(int).flatten()

        # Sort images by their true labels
        for img, label in zip(images, labels):
            if label == 0 and len(class_0_images) < samples_per_class:  # No mask
                class_0_images.append(img)
                class_0_labels.append(label)
            elif label == 1 and len(class_1_images) < samples_per_class:  # With mask
                class_1_images.append(img)
                class_1_labels.append(label)

    # Combine the collected images and labels
    display_images = class_0_images + class_1_images
    display_labels = class_0_labels + class_1_labels

    # Make predictions on the collected images
    predictions = model.predict(np.array(display_images))
    predictions = np.round(predictions).astype(int).flatten()

    # Plot the results
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    fig.suptitle(title, fontsize=16)

    for i, ax in enumerate(axes.flat):
        ax.imshow(display_images[i])
        ax.set_title(f"True: {' Mask' if display_labels[i]==0 else 'No Mask'}\n"
                    f"Pred: {'Mask' if predictions[i]==0 else 'No Mask'}")
        ax.axis("off")

    plt.tight_layout()
    plt.show()

# Visualize predictions on test images
visualize_predictions(test_generator, model, "Test Predictions")

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt
import cv2

def test_single_image(model, image_path, img_height=224, img_width=224):
    """
    Enhanced test function for mask detection model with additional preprocessing
    and more detailed output
    """
    # Load and preprocess the image
    img = load_img(image_path, target_size=(img_height, img_width))
    img_array = img_to_array(img)

    # Additional preprocessing steps
    # Convert to BGR (since MobileNetV2 was trained on BGR images)
    img_array_bgr = img_array[..., ::-1]

    # Normalize
    img_array = img_array_bgr / 255.0

    # Add batch dimension
    img_array = np.expand_dims(img_array, axis=0)

    # Make prediction
    prediction = model.predict(img_array, verbose=0)  # Disable verbose output
    pred_class = np.round(prediction).astype(int)[0][0]
    confidence = prediction[0][0]

    # Prepare labels (0 = mask, 1 = no mask)
    label = "No Mask" if pred_class == 1 else "Mask"
    conf_percentage = confidence if pred_class == 1 else (1 - confidence)

    # Create figure with two subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # Original image
    ax1.imshow(img)
    ax1.set_title('Original Image')
    ax1.axis('off')

    # Preprocessed image
    ax2.imshow(img_array_bgr[0] / 255.0)  # Display normalized BGR image
    ax2.set_title('Preprocessed Image\n(Model Input)')
    ax2.axis('off')

    # Add prediction info as figure suptitle
    plt.suptitle(f'Prediction: {label} (Confidence: {conf_percentage:.2%})\n' +
                f'Raw Model Output: {prediction[0][0]:.4f}',
                color='green' if conf_percentage > 0.9 else 'red',
                y=1.05)

    plt.tight_layout()
    plt.show()

    # Print detailed analysis
    print("\nDetailed Analysis:")
    print("-" * 50)
    print(f"Prediction Class: {label}")
    print(f"Confidence: {conf_percentage:.2%}")
    print(f"Raw Model Output: {prediction[0][0]:.4f}")
    print("-" * 50)
    print("Interpretation Guide:")
    print("• Raw output close to 0 → Model thinks mask is present")
    print("• Raw output close to 1 → Model thinks no mask is present")
    if conf_percentage > 0.9:
        print("\nNote: High confidence prediction (>90%)")

    return pred_class, confidence

# Example usage:
# prediction, confidence = test_single_image(model, "path/to/image.jpg")

# Example usage
image_path = "/content/profile picture.jpg"
prediction, confidence = test_single_image(model, image_path)